version: '3'

services:
  text-generation:
    image: ghcr.io/huggingface/text-generation-inference:1.4
    runtime: nvidia  # Specify the GPU runtime
    #environment:
    #  - HUGGING_FACE_HUB_TOKEN=<your cli READ token>
    ports:
      - "8080:80"
    shm_size: 1g
    volumes:
      - $PWD/data:/data
    command: --model-id meta-llama/Llama-2-7b-chat-hf
